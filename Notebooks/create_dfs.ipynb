{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes the input networks and returns both validation and training datasets.\n",
    "\n",
    "Inputs:\n",
    "- gene-drug network\n",
    "- gene-gene network\n",
    "- gene-disease network\n",
    "- full gene-drug network (to recover removed edges)\n",
    "- output embeddings from BIONIC/BERTwalk\n",
    "\n",
    "Outputs:\n",
    "- `final_df`: dataset for training and testing downstream models (containing gene-drug interactions left)\n",
    "- `validation_df`: dataset for validating downstream models (containing gene-drug interactions removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries and set paths for inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Final_df part\n",
    "path_to_gene_drug = \"\"\n",
    "path_to_gene_gene = \"\"\n",
    "path_to_gene_disease = \"\"\n",
    "\n",
    "path_to_gene_drug_embs = \"\"\n",
    "path_to_gene_gene_embs = \"\"\n",
    "path_to_gene_disease_embs = \"\"\n",
    "path_to_embs = \"\"\n",
    "path_save_final_df = \"\" # where to save final_df\n",
    "\n",
    "n_samples = 10000 # number of samples per group in final_df (positive/negative triplets).\n",
    "\n",
    "# Validation_df part\n",
    "path_to_gene_drug_full = \"\"\n",
    "n_val = 5000 # number of samples per group in validation_df (positive/negative triplets)\n",
    "\n",
    "path_save_validation_df = \"\"\n",
    "\n",
    "path_to_drug_list = \"\"\n",
    "path_to_disease_list = \"\"\n",
    "path_to_train_genes = \"\"\n",
    "# Set seeds\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load networks and embeddings depending on what you used for BIONIC (es. BIONIC outputs embeddings on five_edge nets, use them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load networks\n",
    "gene_drug = pd.read_csv(path_to_gene_drug, sep = \" \", header = None, names = [\"Gene\", \"Drug\", \"Ass\"])\n",
    "gene_disease = pd.read_csv(path_to_gene_disease, sep = \" \", header = None, names = [\"Gene\", \"Disease\", \"Ass\"])\n",
    "gene_gene = pd.read_csv(path_to_gene_gene, sep = \" \", header = None, names = [\"Gene1\", \"Gene2\", \"Ass\"])\n",
    "\n",
    "# Load embeddings\n",
    "embs_drug = pd.read_csv(path_to_gene_drug_embs, sep = \"\\t\", index_col = 0)\n",
    "embs_gene = pd.read_csv(path_to_gene_gene_embs, sep = \"\\t\", index_col = 0)\n",
    "embs_disease = pd.read_csv(path_to_gene_disease_embs, sep = \"\\t\", index_col = 0)\n",
    "\n",
    "# Subset\n",
    "embs_drug = embs_drug[[True if i not in list(embs_gene.index) else False for i in embs_drug.index]]\n",
    "embs_disease = embs_disease[[True if i not in list(embs_gene.index) else False for i in embs_disease.index]]\n",
    "\n",
    "\n",
    "embs = pd.concat([embs_drug, embs_gene, embs_disease])\n",
    "embs = embs[~embs.index.duplicated()]\n",
    "\n",
    "embs = pd.read_csv(path_to_embs, sep = \"\\t\", index_col = 0)\n",
    "\n",
    "# Reconstruct embeddings\n",
    "embs = embs.apply(np.array, axis = 1).to_frame()\n",
    "embs.columns = [\"Embedding\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create __positive__ triplets starting from associations coming from the input networks.\n",
    "This is done with a join between gene-drug network and gene-disease network on column 'Gene'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with id of the triplets (drug - gene - disease)\n",
    "merged_df = pd.merge(gene_drug, gene_disease, on='Gene')\n",
    "\n",
    "# Map IDs to their respective embeddings\n",
    "cols_to_map = [\"Gene\", \"Drug\", \"Disease\"]\n",
    "for col in cols_to_map:\n",
    "    merged_df[col] = merged_df[col].map(embs[\"Embedding\"])\n",
    "\n",
    "\n",
    "# Drop unnecessary columns and add labels\n",
    "merged_df = merged_df[cols_to_map]\n",
    "merged_df[\"Label\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create __negative__ triplets by shuffling embeddings of genes, drugs and diseases at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute list for names of the entities\n",
    "drug_list = pd.read_csv(path_to_drug_list)[\"0\"].tolist()\n",
    "disease_list = pd.read_csv(path_to_disease_list)[\"0\"].tolist()\n",
    "\n",
    "# Create column for entity type\n",
    "embs[\"Entity_type\"] = embs.index.map(lambda x: \"Drug\" if x in drug_list else \"Disease\" if x in disease_list else \"Gene\")\n",
    "\n",
    "# Sample random rows from the dataframe for each entity type (assuming embeddings for different entities are grouped together)\n",
    "random_drug_embeddings = embs[embs['Entity_type'] == 'Drug'].sample(n=round(len(merged_df)), replace=True)\n",
    "random_gene_embeddings = embs[embs['Entity_type'] == 'Gene'].sample(n=round(len(merged_df)), replace=True)\n",
    "random_disease_embeddings = embs[embs['Entity_type'] == 'Disease'].sample(n=round(len(merged_df)), replace=True)\n",
    "\n",
    "# Combine the sampled embeddings into triplets\n",
    "random_triplets_df = pd.DataFrame({\n",
    "    'Gene': random_gene_embeddings['Embedding'].values,\n",
    "    'Drug': random_drug_embeddings['Embedding'].values,\n",
    "    'Disease': random_disease_embeddings['Embedding'].values\n",
    "})\n",
    "\n",
    "# add labels to indicate that these triplets are randomly generated\n",
    "random_triplets_df['Label'] = 0  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter by number of rows (taking `n_samples` rows per group) and save the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(merged_df) > n_samples:\n",
    "    merged_df = merged_df.sample(n=n_samples)\n",
    "    random_triplets_df = random_triplets_df.sample(n=n_samples)\n",
    "\n",
    "# Now concatenate the two dataframes and aggregate the embeddings\n",
    "final_df = pd.concat([merged_df, random_triplets_df], axis = 0, ignore_index=True)\n",
    "\n",
    "# Now aggregate the columns to reform the embeddings\n",
    "final_df[\"Concat_emb\"] = final_df[cols_to_map].apply(np.concatenate, axis = 1)\n",
    "\n",
    "# Drop unnecesssary columns\n",
    "final_df = final_df.drop(cols_to_map, axis = 1)\n",
    "\n",
    "# Save final df\n",
    "final_df.to_csv(path_save_final_df, sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create validation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading full gene-drug network to recover removed edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full gene-drug network\n",
    "gene_drug_full = pd.read_csv(path_to_gene_drug_full, sep = \" \", header = None, names = [\"Gene\", \"Drug\", \"Ass\"])\n",
    "\n",
    "# Concatenate and remove duplicates (together with their first copy) to obtain only removed edges\n",
    "gene_drug_val = pd.concat([gene_drug_full, gene_drug], ignore_index=True).drop_duplicates(keep = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create __positive__ triplets starting from removed gene-drug associations.\n",
    "This is done similarly as done for final_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct the previous associations\n",
    "removed_true_ass = pd.merge(gene_drug_val, gene_disease, on = \"Gene\")\n",
    "removed_true_ass = removed_true_ass.drop([\"Ass_x\", \"Ass_y\"], axis = 1)\n",
    "\n",
    "# Retain only test genes\n",
    "only_train_genes = pd.read_csv(path_to_train_genes, header=None)[0].tolist()\n",
    "removed_true_ass = removed_true_ass[~removed_true_ass[\"Gene\"].isin(only_train_genes)]\n",
    "\n",
    "# Now map to embeddings\n",
    "for col in removed_true_ass.columns:\n",
    "    removed_true_ass[col] = removed_true_ass[col].map(embs[\"Embedding\"])\n",
    "\n",
    "# Add labels \n",
    "removed_true_ass[\"Label\"] = 1\n",
    "\n",
    "\n",
    "# Fix order of columns\n",
    "removed_true_ass = removed_true_ass[[\"Gene\", \"Drug\", \"Disease\", \"Label\"]]\n",
    "\n",
    "# Sample n_val rows\n",
    "removed_true_ass = removed_true_ass.sample(n_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create __negative__ triplets by shuffling embeddings of genes, drugs and diseases at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample random rows from the dataframe for each entity type (assuming embeddings for different entities are grouped together)\n",
    "random_drug_embeddings = embs[embs['Entity_type'] == 'Drug'].sample(n=n_val, replace=True)\n",
    "random_gene_embeddings = embs[embs['Entity_type'] == 'Gene'].sample(n=n_val, replace=True)\n",
    "random_disease_embeddings = embs[embs['Entity_type'] == 'Disease'].sample(n=n_val, replace=True)\n",
    "\n",
    "# Combine the sampled embeddings into triplets\n",
    "random_triplets_val = pd.DataFrame({\n",
    "    'Gene': random_gene_embeddings['Embedding'].values,\n",
    "    'Drug': random_drug_embeddings['Embedding'].values,\n",
    "    'Disease': random_disease_embeddings['Embedding'].values\n",
    "})\n",
    "\n",
    "# Optionally, you can add labels to indicate that these triplets are randomly generated\n",
    "random_triplets_val['Label'] = 0  # Assuming 0 indicates randomly generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `validation_df` by concatenating positive and negative triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create the two validation dataframes\n",
    "validation_embs = pd.concat([removed_true_ass, random_triplets_val], axis = 0, ignore_index=True)\n",
    "\n",
    "# Concatenate embeddings and drop unnecessary columns\n",
    "validation_embs[\"Concat_emb\"] = validation_embs[[\"Gene\", \"Drug\", \"Disease\"]].apply(np.concatenate, axis = 1)\n",
    "validation_embs = validation_embs.drop([\"Gene\", \"Drug\", \"Disease\"], axis = 1)\n",
    "\n",
    "# Save df\n",
    "validation_embs.to_csv(path_save_validation_df, sep = \"\\t\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shasha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
